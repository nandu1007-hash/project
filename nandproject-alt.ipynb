{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport os\nfrom PIL import Image\nimport numpy as np\nfrom tqdm import tqdm\n\nclass BrainTumorDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n        \n        self.images = []\n        self.labels = []\n        \n        # Load all image paths and labels\n        for class_name in self.classes:\n            class_dir = os.path.join(root_dir, class_name)\n            for img_name in os.listdir(class_dir):\n                self.images.append(os.path.join(class_dir, img_name))\n                self.labels.append(self.class_to_idx[class_name])\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        image = Image.open(img_path).convert('RGB')\n        label = self.labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2024-11-12T12:00:04.858572Z","iopub.execute_input":"2024-11-12T12:00:04.858995Z","iopub.status.idle":"2024-11-12T12:00:04.869084Z","shell.execute_reply.started":"2024-11-12T12:00:04.858956Z","shell.execute_reply":"2024-11-12T12:00:04.868076Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"\nclass TransformerBlock(nn.Module):\n    def __init__(self, embed_dim, num_heads, dropout=0.1):\n        super().__init__()\n        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n        self.norm1 = nn.LayerNorm(embed_dim)\n        self.norm2 = nn.LayerNorm(embed_dim)\n        self.ff = nn.Sequential(\n            nn.Linear(embed_dim, embed_dim * 4),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            nn.Linear(embed_dim * 4, embed_dim)\n        )\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        attended, _ = self.attention(x, x, x)\n        x = self.norm1(x + self.dropout(attended))\n        x = self.norm2(x + self.dropout(self.ff(x)))\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-11-12T12:00:05.273465Z","iopub.execute_input":"2024-11-12T12:00:05.273840Z","iopub.status.idle":"2024-11-12T12:00:05.281476Z","shell.execute_reply.started":"2024-11-12T12:00:05.273804Z","shell.execute_reply":"2024-11-12T12:00:05.280479Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class BrainTumorClassifier(nn.Module):\n    def __init__(self, num_classes=4):\n        super().__init__()\n        \n        # CNN Feature Extraction\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n        \n        self.feature_size = 128 * (512 // 8) * (512 // 8)\n        self.embed_dim = 256\n        \n        self.projection = nn.Linear(128, self.embed_dim)\n        \n        self.pos_embedding = nn.Parameter(torch.randn(1, (512 // 8) * (512 // 8), self.embed_dim))\n        \n        self.transformer_blocks = nn.ModuleList([\n            TransformerBlock(self.embed_dim, num_heads=8)\n            for _ in range(2)\n        ])\n        \n        # Classification head\n        self.classifier = nn.Sequential(\n            nn.Linear(self.embed_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, num_classes)\n        )\n        \n    def forward(self, x):\n        batch_size = x.size(0)\n        x = self.cnn(x)\n        x = x.view(batch_size, 128, -1).permute(0, 2, 1)\n        x = self.projection(x)\n        \n        x = x + self.pos_embedding\n        \n        for block in self.transformer_blocks:\n            x = block(x)\n        x = x.mean(dim=1)\n        x = self.classifier(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-11-12T12:00:06.160082Z","iopub.execute_input":"2024-11-12T12:00:06.160962Z","iopub.status.idle":"2024-11-12T12:00:06.172129Z","shell.execute_reply.started":"2024-11-12T12:00:06.160921Z","shell.execute_reply":"2024-11-12T12:00:06.171051Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, device, num_epochs=50):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.1)\n    \n    best_val_loss = float('inf')\n    best_model_state = None\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0\n        train_correct = 0\n        train_total = 0\n        \n        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            train_total += labels.size(0)\n            train_correct += predicted.eq(labels).sum().item()\n        \n        model.eval()\n        val_loss = 0\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_total += labels.size(0)\n                val_correct += predicted.eq(labels).sum().item()\n        \n        train_loss = train_loss / len(train_loader)\n        train_acc = 100. * train_correct / train_total\n        val_loss = val_loss / len(val_loader)\n        val_acc = 100. * val_correct / val_total\n        \n        print(f'Epoch: {epoch+1}')\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n        \n        scheduler.step(val_loss)\n        \n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_state = model.state_dict().copy()\n    \n    model.load_state_dict(best_model_state)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:00:07.002791Z","iopub.execute_input":"2024-11-12T12:00:07.003566Z","iopub.status.idle":"2024-11-12T12:00:07.016362Z","shell.execute_reply.started":"2024-11-12T12:00:07.003525Z","shell.execute_reply":"2024-11-12T12:00:07.015380Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# def main():\n#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    \n#     transform = transforms.Compose([\n#         transforms.Resize((512, 512)),\n#         transforms.RandomHorizontalFlip(),\n#         transforms.RandomRotation(10),\n#         transforms.ToTensor(),\n#         transforms.Normalize(mean=[0.485, 0.456, 0.406], \n#                            std=[0.229, 0.224, 0.225])\n#     ])\n    \n#     train_dataset = BrainTumorDataset(\n#         root_dir='/kaggle/input/brain-tumor-mri-dataset/Training',\n#         transform=transform\n#     )\n    \n#     test_dataset = BrainTumorDataset(\n#         root_dir='/kaggle/input/brain-tumor-mri-dataset/Testing',\n#         transform=transforms.Compose([\n#             transforms.Resize((512, 512)),\n#             transforms.ToTensor(),\n#             transforms.Normalize(mean=[0.485, 0.456, 0.406], \n#                                std=[0.229, 0.224, 0.225])\n#         ])\n#     )\n    \n#     train_loader = DataLoader(\n#         train_dataset, \n#         batch_size=32,\n#         shuffle=True,\n#         num_workers=4\n#     )\n    \n#     test_loader = DataLoader(\n#         test_dataset,\n#         batch_size=32,\n#         shuffle=False,\n#         num_workers=4\n#     )\n    \n#     model = BrainTumorClassifier().to(device)\n    \n#     model = train_model(model, train_loader, test_loader, device)\n    \n#     torch.save(model.state_dict(), 'brain_tumor_classifier.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T11:26:19.262529Z","iopub.execute_input":"2024-11-12T11:26:19.262934Z","iopub.status.idle":"2024-11-12T11:26:19.272650Z","shell.execute_reply.started":"2024-11-12T11:26:19.262897Z","shell.execute_reply":"2024-11-12T11:26:19.271652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def main(N=10):  # N is the number of images per class\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    print(f\"Loading {N} images per class\")\n    \n    transform = transforms.Compose([\n        transforms.Resize((512, 512)),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                           std=[0.229, 0.224, 0.225])\n    ])\n    \n    # Create custom sampler class to limit images\n    class LimitedDataset(Dataset):\n        def __init__(self, root_dir, transform=None, n_per_class=None):\n            self.root_dir = root_dir\n            self.transform = transform\n            self.classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n            self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n            \n            self.images = []\n            self.labels = []\n            \n            # Load limited number of images per class\n            for class_name in self.classes:\n                class_dir = os.path.join(root_dir, class_name)\n                files = sorted([f for f in os.listdir(class_dir) \n                              if f.endswith(('.jpg', '.jpeg', '.png'))])\n                \n                # Limit files if n_per_class is specified\n                if n_per_class is not None:\n                    files = files[:n_per_class]\n                \n                for img_name in files:\n                    self.images.append(os.path.join(class_dir, img_name))\n                    self.labels.append(self.class_to_idx[class_name])\n                    \n            print(f\"Loaded total {len(self.images)} images from {root_dir}\")\n            \n        def __len__(self):\n            return len(self.images)\n        \n        def __getitem__(self, idx):\n            img_path = self.images[idx]\n            image = Image.open(img_path).convert('RGB')\n            label = self.labels[idx]\n            \n            if self.transform:\n                image = self.transform(image)\n            \n            return image, label\n    \n    # Create datasets with limited images\n    train_dataset = LimitedDataset(\n        root_dir='/kaggle/input/brain-tumor-mri-dataset/Training',\n        transform=transform,\n        n_per_class=N\n    )\n    \n    test_dataset = LimitedDataset(\n        root_dir='/kaggle/input/brain-tumor-mri-dataset/Testing',\n        transform=transforms.Compose([\n            transforms.Resize((512, 512)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                               std=[0.229, 0.224, 0.225])\n        ]),\n        n_per_class=N//5  # Using 20% of N for testing\n    )\n    \n    batch_size = min(32, N)  # Ensure batch size isn't larger than dataset\n    \n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size,\n        shuffle=True,\n        num_workers=4\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=4\n    )\n    \n    model = BrainTumorClassifier().to(device)\n    \n    model = train_model(model, train_loader, test_loader, device)\n    \n    torch.save(model.state_dict(), f'brain_tumor_classifier_{N}samples.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:00:49.445924Z","iopub.execute_input":"2024-11-12T12:00:49.446857Z","iopub.status.idle":"2024-11-12T12:00:49.463164Z","shell.execute_reply.started":"2024-11-12T12:00:49.446814Z","shell.execute_reply":"2024-11-12T12:00:49.462217Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-12T12:00:49.724792Z","iopub.execute_input":"2024-11-12T12:00:49.725609Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nLoading 10 images per class\nLoaded total 40 images from /kaggle/input/brain-tumor-mri-dataset/Training\nLoaded total 8 images from /kaggle/input/brain-tumor-mri-dataset/Testing\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/50: 100%|██████████| 4/4 [00:00<00:00,  4.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1\nTrain Loss: 1.5721, Train Acc: 32.50%\nVal Loss: 1.4560, Val Acc: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50: 100%|██████████| 4/4 [00:00<00:00,  4.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2\nTrain Loss: 1.5355, Train Acc: 30.00%\nVal Loss: 1.3979, Val Acc: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/50: 100%|██████████| 4/4 [00:00<00:00,  4.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3\nTrain Loss: 1.5650, Train Acc: 20.00%\nVal Loss: 1.4307, Val Acc: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/50: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4\nTrain Loss: 1.4670, Train Acc: 22.50%\nVal Loss: 1.4237, Val Acc: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/50: 100%|██████████| 4/4 [00:00<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5\nTrain Loss: 1.5244, Train Acc: 20.00%\nVal Loss: 1.4198, Val Acc: 25.00%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/50:   0%|          | 0/4 [00:00<?, ?it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}